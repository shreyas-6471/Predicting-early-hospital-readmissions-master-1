# -*- coding: utf-8 -*-
"""06_random_forest_and_cost_benefit_threshold_tuning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BtuH5Li0q8s8tuVCnGptqB0rWqQqKZTG

# Tree-based classifiers (DT, RF, ExtraRandomTrees, GradientBoostedTrees, XGBoost):

Classifying with supervised learning whether diabetic patients are admitted, and if they are, if it's before or after 30 days.

Using the dataset from here: https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008

## TODO:
- additional cleanup and standardization
- randomsearchcv for randomforest
- randomsearchcv for gradientboostedtrees
- randomsearchcv for xgboost
- cleanup so that it's obvious what's going on with the cost function classification threshold tuning
- make it obvious where the model is being retrained on a subset of features for the purpose of creating the flask app model
- discuss the importance of model evaluation metric and why I settled on f1 macro or recall macro instead of something like accuracy

## Model evaluation and final model creation:

Once the best model was determined based on f1 macro score, the model was retrained on a subset of features for the purpose of creating the flask app model.

25 features seemed to be a reasonable amount to balance the effort it would take to input them into the dash UI while still retaining good model performance.
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline







#import matplotlib.cm as cm
import random


#from sklearn._forest  import RandomForestClassifier
from sklearn.ensemble._forest import RandomForestClassifier

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import BaggingClassifier

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV

from sklearn import metrics

import pickle

with open("y_train_liv.pkl", 'rb') as picklefile: 
    y_train = pickle.load(picklefile)

with open("y_test_liv.pkl", 'rb') as picklefile: 
    y_test = pickle.load(picklefile)

with open("x_train_liv.pkl", 'rb') as picklefile: 
    x_train = pickle.load(picklefile)

with open("x_test_liv.pkl", 'rb') as picklefile: 
    x_test = pickle.load(picklefile)

"""## Binarizing classes:"""

y_test = y_test.str.replace('>30','NO')
y_train = y_train.str.replace('>30','NO')

print(x_test.values[0])
print("@@@@@@@@@@@@@@@@@@@@@@@")
"""## Decision tree with balanced class weights on single random train-test split:"""

"""## Random forest with balanced class weights on single random train-test split:"""



"""## SMOTE:"""

sm = SMOTE(random_state=42)
x_train_smote, y_train_smote = sm.fit_resample(x_train, y_train)

# sns.countplot(y_train);

# sns.countplot(y_train_smote);



rus = RandomUnderSampler(random_state=0)
x_train_undersampled, y_train_undersampled = rus.fit_resample(x_train, y_train)


randomforest = RandomForestClassifier(n_estimators=300, min_samples_split=70)
randomforest.fit(x_train_undersampled, y_train_undersampled)
y_pred = randomforest.predict(x_test)
print(metrics.classification_report(y_test, y_pred))

# pickle model for predictor app
with open('randomforest.pkl', 'wb') as picklefile:
    pickle.dump(randomforest, picklefile)
